{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62ca00-646b-4d1d-afb0-ef88cbfe8ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84968fe-000f-479e-b4a3-96677267de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.21-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (3.3.2)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (5.3.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (4.12.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.11.16-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 262.1/981.5 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 524.3/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------ ------- 786.4/981.5 kB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ 981.5/981.5 kB 990.3 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (2.1.3)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.14.3-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.42.5-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (1.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\anaconda3\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->unstructured) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->unstructured) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk->unstructured) (0.4.6)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->unstructured) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->unstructured) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->unstructured) (2025.4.26)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-25.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (44.0.1)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (1.0.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (0.28.1)\n",
      "Collecting pydantic>=2.11.2 (from unstructured-client->unstructured)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: pypdf>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (6.4.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.21)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore>=1.0.9->unstructured-client->unstructured) (0.16.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.6.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.11.2->unstructured-client->unstructured)\n",
      "  Downloading pydantic_core-2.41.5-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-extensions (from unstructured)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.0)\n",
      "Downloading unstructured-0.18.21-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "   ---------------------------------------- 0.0/608.4 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/608.4 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 524.3/608.4 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 608.4/608.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading python_iso639-2025.11.16-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading rapidfuzz-3.14.3-cp313-cp313-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.42.5-py3-none-any.whl (216 kB)\n",
      "Downloading aiofiles-25.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 922.0 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.0/2.0 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.0 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993250 sha256=4c56b53bcbeb77481c395e1bb5240dacac1c2b4f6fd6491c81efb2003987e770\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\eb\\87\\25\\2dddf1c94e1786054e25022ec5530bfed52bad86d882999c48\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, typing-extensions, rapidfuzz, python-magic, python-iso639, olefile, langdetect, html5lib, emoji, backoff, aiofiles, python-oxmsg, pydantic-core, pydantic, unstructured-client, unstructured\n",
      "\n",
      "  Attempting uninstall: typing-extensions\n",
      "\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "   -- -------------------------------------  1/16 [typing-extensions]\n",
      "   ----- ----------------------------------  2/16 [rapidfuzz]\n",
      "   ----- ----------------------------------  2/16 [rapidfuzz]\n",
      "   ------------ ---------------------------  5/16 [olefile]\n",
      "   --------------- ------------------------  6/16 [langdetect]\n",
      "   ----------------- ----------------------  7/16 [html5lib]\n",
      "   ----------------- ----------------------  7/16 [html5lib]\n",
      "   -------------------- -------------------  8/16 [emoji]\n",
      "   --------------------------- ------------ 11/16 [python-oxmsg]\n",
      "  Attempting uninstall: pydantic-core\n",
      "   --------------------------- ------------ 11/16 [python-oxmsg]\n",
      "    Found existing installation: pydantic_core 2.27.1\n",
      "   --------------------------- ------------ 11/16 [python-oxmsg]\n",
      "    Uninstalling pydantic_core-2.27.1:\n",
      "   --------------------------- ------------ 11/16 [python-oxmsg]\n",
      "      Successfully uninstalled pydantic_core-2.27.1\n",
      "   --------------------------- ------------ 11/16 [python-oxmsg]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "  Attempting uninstall: pydantic\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "    Found existing installation: pydantic 2.10.3\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "    Uninstalling pydantic-2.10.3:\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "      Successfully uninstalled pydantic-2.10.3\n",
      "   ------------------------------ --------- 12/16 [pydantic-core]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   ----------------------------------- ---- 14/16 [unstructured-client]\n",
      "   ----------------------------------- ---- 14/16 [unstructured-client]\n",
      "   ----------------------------------- ---- 14/16 [unstructured-client]\n",
      "   ----------------------------------- ---- 14/16 [unstructured-client]\n",
      "   ----------------------------------- ---- 14/16 [unstructured-client]\n",
      "   ----------------------------------- ---- 14/16 [unstructured-client]\n",
      "   ------------------------------------- -- 15/16 [unstructured]\n",
      "   ------------------------------------- -- 15/16 [unstructured]\n",
      "   ------------------------------------- -- 15/16 [unstructured]\n",
      "   ------------------------------------- -- 15/16 [unstructured]\n",
      "   ------------------------------------- -- 15/16 [unstructured]\n",
      "   ------------------------------------- -- 15/16 [unstructured]\n",
      "   ------------------------------------- -- 15/16 [unstructured]\n",
      "   ------------------------------------- -- 15/16 [unstructured]\n",
      "   ------------------------------------- -- 15/16 [unstructured]\n",
      "   ---------------------------------------- 16/16 [unstructured]\n",
      "\n",
      "Successfully installed aiofiles-25.1.0 backoff-2.2.1 emoji-2.15.0 filetype-1.2.0 html5lib-1.1 langdetect-1.0.9 olefile-0.47 pydantic-2.12.5 pydantic-core-2.41.5 python-iso639-2025.11.16 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.14.3 typing-extensions-4.15.0 unstructured-0.18.21 unstructured-client-0.42.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\user\\anaconda3\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe513fe-9f34-43c6-a637-a5a96e026679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in c:\\users\\user\\anaconda3\\lib\\site-packages (0.18.21)\n",
      "Collecting python-pptx\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (3.3.2)\n",
      "Requirement already satisfied: filetype in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (5.3.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (2.15.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (2025.11.16)\n",
      "Requirement already satisfied: langdetect in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (2.1.3)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (3.14.3)\n",
      "Requirement already satisfied: backoff in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (4.15.0)\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (0.42.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (1.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (5.9.0)\n",
      "Requirement already satisfied: python-oxmsg in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (0.0.2)\n",
      "Requirement already satisfied: html5lib in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-pptx) (11.1.0)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
      "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\anaconda3\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->unstructured) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->unstructured) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk->unstructured) (0.4.6)\n",
      "Requirement already satisfied: olefile in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->unstructured) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->unstructured) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->unstructured) (2025.4.26)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (25.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (44.0.1)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (1.0.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.11.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (2.12.5)\n",
      "Requirement already satisfied: pypdf>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (6.4.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.21)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore>=1.0.9->unstructured-client->unstructured) (0.16.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.0)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
      "Installing collected packages: XlsxWriter, python-pptx\n",
      "\n",
      "   ---------------------------------------- 0/2 [XlsxWriter]\n",
      "   ---------------------------------------- 0/2 [XlsxWriter]\n",
      "   -------------------- ------------------- 1/2 [python-pptx]\n",
      "   -------------------- ------------------- 1/2 [python-pptx]\n",
      "   -------------------- ------------------- 1/2 [python-pptx]\n",
      "   -------------------- ------------------- 1/2 [python-pptx]\n",
      "   ---------------------------------------- 2/2 [python-pptx]\n",
      "\n",
      "Successfully installed XlsxWriter-3.2.9 python-pptx-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured python-pptx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1a0855-bb54-40f6-9b20-dbda5a2973d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='gemma:2b')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=\"gemma:2b\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9a78002-5868-4477-aa3e-47c4e886819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, UnstructuredPowerPointLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path=r\"..\\data\\books\",\n",
    "    glob=\"**/*.pptx\",\n",
    "    loader_cls=UnstructuredPowerPointLoader\n",
    ")\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a50c4ca-5fe8-4985-a149-63303d63075d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\books\\\\Feature Engineering.pptx'}, page_content=\"Feature Engineering\\n\\nFeature Engineering is like giving your data a makeover before it meets a machine learning model.\\n\\nIt means cleaning, creating, transforming, selecting, or removing features (columns) so the model can understand patterns more clearly.\\n\\nIn short — it’s the art of turning raw data into smart data that helps machines learn better.\\n\\nWhy do we need feature engineering?\\n\\nWe need feature engineering because it helps improve model performance by turning raw data into meaningful inputs — making patterns clearer and predictions more accurate.\\n\\n10\\n\\n\\n\\nImagine you start building a machine learning model using raw data like this:\\n\\nIf you train a model directly on this, it’ll struggle — because of missing ages, inconsistent formats, and unclear values.\\n\\nThat’s where feature engineering comes in. It cleans and prepares such data:\\n\\nFills missing values, ﬁxes date formats\\n\\nConverts “Gender” to numbers (0/1)\\n\\nCreates new features like “Monthly_Spending” or “Days_Since_Last_Purchase”\\n\\nThis turns raw, messy data into structured, meaningful input that helps the model learn patterns and predict accurately.\\n\\n10\\n\\n\\n\\nUnderstanding all steps of feature engineering with a case study\\n\\nCase Study: Feature Engineering at a Card Company (e.g., Mastercard)\\n\\nScenario\\n\\nMastercard handles millions of transactions daily worldwide — from credit cards, \\tATMs, and online payments.\\n\\nEach transaction includes details like amount, location, merchant type, time, device \\tID, and user history.\\n\\nManaging this massive, fast-ﬂowing data requires high accuracy, security, and \\treal-time processing.\\n\\nProblem Statement\\n\\nThe company faces challenges such as:\\n\\n10\\n\\n\\n\\nRising fraudulent transactions and suspicious payment patterns.\\n\\nInconsistent data from multiple systems and countries.\\n\\nDifﬁculty in real-time fraud detection, as data streams in every second.\\n\\nA need for a machine learning model that can identify and block fraud instantly before payment approval.\\n\\nWhat the Data Science Team Does\\n\\nTo tackle this, Mastercard’s data scientists and ML engineers start with feature engineering — the most critical step before model training.\\n\\nThey can’t feed raw transaction data directly into the ML model — it’s too noisy, inconsistent, and incomplete.\\n\\nSo they perform feature engineering to make the data “model-ready.”\\n\\nFeature Engineering on Mastercard Transaction Data\\n\\nOnce the raw transaction data is collected, the data science team begins feature engineering to prepare it for the fraud detection model.\\n\\nData Cleaning\\n\\nRemove duplicate or incomplete transactions.\\n\\nStandardize date, time, and currency formats across countries.\\n\\nFix missing values (e.g., merchant or location) using imputation or reliable reference data.\\n\\n→ Intuition: Clean data ensures reliability and prevents false fraud alerts.\\n\\nHandling Missing Values\\n\\nFill missing merchant types or locations using the user's past behavior or averages.\\n\\n→ Intuition: Maintains data completeness and consistency for model training.\\n\\n10\\n\\n\\n\\nEncoding Categorical Data\\n\\nConvert text columns like “merchant type” or “payment mode” into numerical form using one-hot or label encoding.\\n\\n→ Intuition: ML models understand numbers better than text.\\n\\n4. Feature Scaling\\n\\n10\\n\\n\\n\\nNormalize or standardize features like transaction amount and time gap (e.g., using Z-score or Min-Max scaling).\\n\\n→ Intuition: Prevents large numerical values from dominating smaller ones.\\n\\nFeature Transformation\\n\\nApply log or power transformations to reduce skewness in transaction amounts.\\n\\nConvert timestamps into parts like hour of day or day of week for better trend detection.\\n\\n→ Intuition: Makes data more normally distributed and interpretable for the model.\\n\\nFeature Creation\\n\\nDerive new features such as:\\n\\nNumber of transactions in the last 5 minutes\\n\\nAverage daily transaction per user\\n\\nDistance between current and last transaction location\\n\\n→ Intuition: Captures behavioral patterns to detect unusual activity.\\n\\nFeature Extraction\\n\\nUse mathematical or statistical methods (like PCA or embedding models) to derive compact representations from high-dimensional data.\\n\\n→ Intuition: Reduces noise and highlights the most useful information.\\n\\nOutlier Handling\\n\\nDetects and treats extreme transaction amounts using IQR or z-score.\\n\\n→ Intuition: Prevents anomalies from skewing model predictions.\\n\\n9. Feature Selection\\n\\n10\\n\\n\\n\\nDrop irrelevant or repetitive columns (like anonymized card IDs or low-impact features).\\n\\nUse correlation checks or feature importance scores.\\n\\n→ Intuition: Keeps only what truly adds value to model performance.\\n\\nEDA vs Feature Engineering\\n\\nIf we already explore data during EDA, then where exactly does feature engineering fit in — is it part of EDA or model building?\\n\\nFeature engineering is technically a bridge between EDA and model building.\\n\\nTechnically, we explore and understand data during EDA, but we create and reﬁne features during feature engineering to make that data usable for machine learning models.\\n\\n10\\n\\n\\n\\nSo, it’s not EDA itself, but a crucial part of the ML model preparation phase, guided by insights discovered in EDA.\\n\\nHence, in practice as well, keep EDA and model-building in separate notebooks. EDA focuses on understanding and visualizing data, while model notebooks handle preprocessing, feature engineering, and training.\\n\\nThis separation keeps workﬂows clean, modular, and easier to debug or reuse.\\n\\nWhat next after feature engineering?\\n\\nAfter feature engineering, we usually do data splitting and data balancing.\\n\\nWe split the data into training, validation, and test sets so the model learns, tunes, \\tand is ﬁnally tested on unseen data — this prevents overﬁtting.\\n\\n10\\n\\n\\n\\nThen, we do data balancing (like oversampling or undersampling) to ﬁx unequal \\tclass counts, ensuring the model doesn’t get biased toward the majority class.\\n\\nThese steps aren’t part of feature engineering because they don’t change or create features — they deal with how data is organized and distributed for fair, effective model training.\\n\\nFAQ’s regarding feature engineering\\n\\n1. How do we know which features truly impact the model’s prediction?\\n\\n10\\n\\n\\n\\nAns. We can ﬁnd which features impact a model’s prediction using feature importance techniques — like model coefﬁcients (for linear models), feature importance scores (for tree models), or SHAP and LIME for deeper interpretability.\\n\\nThese methods show how much each feature contributes to the model’s output.\\n\\nHow do we engineer features for text, images, or audio data?\\n\\nAns. We engineer features from text, images, or audio by converting them into numerical form —\\n\\nFor text: use word counts, TF-IDF, or embeddings.\\n\\nFor images: extract pixel values or deep features from CNNs.\\n\\nFor audio: use features like MFCCs, pitch, or frequency patterns.\\n\\n3. What happens if we skip feature engineering altogether?\\n\\nAns. If we skip feature engineering: the model gets raw, unstructured data and may fail to learn useful patterns — leading to poor accuracy.\\n\\nCan bad feature engineering make a good model perform poorly?\\n\\nAns. Bad feature engineering: yes, it can make even a strong model perform poorly, because wrong or noisy features confuse the model and reduce its predictive power.\\n\\nHow does EDA guide feature engineering?\\n\\n10\\n\\n\\n\\nAns. EDA helps us understand data patterns, correlations, and issues — guiding what features to create, transform, or remove.\\n\\nWhen should we stop creating new features?\\n\\nAns. Stop when new features don’t improve model performance or add redundancy, and the model becomes complex without real gain.\\n\\nHow do we handle unseen categories in test data?\\n\\nAns. Use techniques like “unknown” category tagging, frequency encoding, or models that handle unseen values gracefully (like tree-based models).\\n\\nDoes feature engineering differ for deep learning models?\\n\\nAns. Yes — deep learning often needs less manual feature engineering, as models learn features automatically from raw data.\\n\\nHow do domain experts help in creating better features?\\n\\nAns. They provide real-world insights that guide meaningful feature creation — linking data patterns to actual business or user behavior.\\n\\nWhat do we do in feature scaling?\\n\\nAns. In feature scaling, we adjust numerical values so all features are on a similar range or scale.\\n\\nThis helps models learn faster and treat each feature equally.\\n\\n10\\n\\n\\n\\nCommon methods:\\n\\nNormalization (Min-Max Scaling): rescale values between 0 and 1.\\n\\nStandardization (Z-score Scaling): center data around mean 0 and standard deviation 1.\\n\\n10\\n\\n\\n\\n11.Why is feature scaling really impactful?\\n\\nAns. Feature scaling is impactful because it makes all features contribute equally to the model’s learning process.\\n\\nWithout scaling, features with large values (like income) can dominate smaller ones (like age), causing biased results.\\n\\nIt also helps models like linear regression, k-means, and neural networks converge faster and perform more accurately.\\n\\n10\"),\n",
       " Document(metadata={'source': '..\\\\data\\\\books\\\\Introduction to Machine Learning.pptx'}, page_content='Introduction to Machine Learning\\n\\n\\n\\nDefinition:\\x0bMachine Learning (ML) is a branch of Artificial Intelligence that allows computers to learn from data and make predictions or decisions without being explicitly programmed.\\n\\nBut how? \\n\\nInstead of giving exact rules, we give the machine examples (data) — and it learns the pattern on its own.\\n\\n\\n\\nFor Example:\\x0bIf we show the model thousands of pictures of cats and dogs, it learns to identify which is which — even for new images it has never seen before.\\n\\nGoal:\\x0bTo make computers automatically improve with experience and handle tasks like prediction, classification, and decision-making.\\n\\n\\n\\nWhy We Need Machine Learning\\n\\n1. Solves difficult problems\\x0b Machine learning can find patterns and answers in situations that are too complex for humans to solve easily.\\n\\n2. Handles huge amounts of data\\x0b It can study and learn from millions of data points much faster than people can.\\n\\n3. Automates repetitive tasks\\x0b It can do the same kind of work over and over again without getting tired or making mistakes.\\n\\n4. Improves over time\\x0b The more data it sees, the smarter it becomes and the better its predictions get.\\n\\n\\n\\n\\n\\nExample:\\n\\nImagine you’re teaching a computer how to tell if an email is spam or not.\\n\\nYou give lots of examples of emails — some marked “spam,” some “not spam.”\\x0b\\n\\nThe computer looks for patterns, like words such as “win,” “offer,” or “free.”\\x0b\\n\\nAfter learning these patterns, it can guess on its own whether a new email is spam or not.\\x0b\\n\\nAs it sees more emails, it keeps improving its guesses.\\n\\n\\n\\nReal-World Case Studies: How ML Works in Action\\n\\nCase Study 1: Paytm – Smarter Fraud Detection\\n\\nPaytm handles millions of payments daily — far too many for humans to check.\\x0b So, it uses ML models trained on past transactions to spot fraud patterns.\\n\\nWhen you make a payment, the model instantly checks:\\n\\nIs the amount unusually high?\\n\\nIs it from a new device or location?\\n\\nHas this receiver been flagged before?\\n\\nIf anything seems suspicious, it blocks the payment immediately.\\x0bEach new case helps the model learn and improve over time.\\n\\n\\n\\nCase Study 2: Healthcare – Predicting Diseases Early\\n\\nHospitals get thousands of patient reports daily — too much for doctors to analyze one by one.\\x0bML models trained on past data (symptoms, test results, outcomes) help identify risks early.\\n\\nWhen a new report arrives, the model looks for:\\n\\nPatterns similar to past heart or diabetes cases\\n\\nUnusual test values\\x0b\\n\\nIf it detects risk, it alerts doctors for faster diagnosis and treatment.\\x0bResult: quicker decisions, better care, and continuous learning with every patient.\\n\\n\\n\\nWhy Machine Learning Is Becoming a Big Part of Our Daily Lives\\n\\nData Growth – Every photo, message, or click adds to the huge pool of data that helps ML models learn better.\\x0b\\n\\nComputing Power – With faster and cheaper computers and cloud systems, ML can now handle complex tasks easily.\\x0b\\n\\nInternet Usage – The more we go online, the more data we generate — and ML learns from it all.\\x0b\\n\\nAutomation Needs – Businesses want machines to handle routine work, so ML steps in to make things faster and more efficient.\\x0b\\n\\nPersonalization – People love getting customized suggestions — from shopping to movies — and ML makes that happen.\\x0b\\n\\nSmart Devices (IoT) – Our phones, cars, and home gadgets keep sending real-time data that ML uses to make smarter systems.\\x0b\\n\\nSmarter Algorithms – New techniques like deep learning help machines do things once thought impossible, like recognizing faces or understanding speech.\\n\\n\\n\\nTypes of machine learning:\\n\\nLet’s take one example to make everything easy to relate:\\x0bExample: Imagine you’re teaching a computer to recognize fruits (apples, bananas, and oranges).\\n\\n1. Supervised Learning\\n\\nIdea: The computer learns with the help of labeled data — means you already know the right answers.\\n\\nExample:\\x0bYou give the model hundreds of fruit images, each labeled — “this is an apple,” “this is a banana,” etc.\\x0bThe model learns the relationship between the image features (like color, shape, size) and the labels.\\n\\n\\n\\nWhen used:\\n\\nWhen we have past data with known outcomes.\\n\\nFor prediction or classification tasks.\\n\\nReal-life examples:\\x0bEmail spam detection, price prediction, disease diagnosis.\\n\\n\\n\\n2. Unsupervised Learning\\n\\nIdea: The computer learns without labels — it tries to find patterns or groups on its own.\\n\\nExample:\\x0bNow, you give the model a bunch of fruit images, but don’t tell which is which.\\x0b It observes the data and groups similar fruits together — apples with apples, bananas with bananas — based only on their features.\\n\\nWhen used:\\n\\nWhen data has no predefined labels.\\n\\nFor finding structure or hidden patterns.\\n\\nReal-life examples:\\x0bCustomer segmentation, market basket analysis, grouping similar songs or movies.\\n\\n\\n\\n\\n\\n3. Semi-Supervised Learning\\n\\nIdea: A mix of both — some data is labeled, most is not. The model uses the few labeled examples to help classify the rest.\\n\\nExample:\\x0bYou label only 50 fruit images (apple, banana, orange) but have 1000 total images.\\x0bThe model learns from those few labeled examples and guesses the rest by finding similarities.\\n\\n\\n\\nWhen used:\\n\\nWhen labeling all data is costly or time-consuming.\\n\\nReal-life examples:\\x0bSpeech recognition, web content classification, medical imaging.\\n\\n\\n\\n4. Reinforcement Learning\\n\\nIdea: The computer learns by trial and error, getting rewards or penalties for its actions — just like humans learn from experience.\\n\\nExample:\\x0b You have a robot trying to pick the right fruit from a basket.\\n\\nIf it picks an apple correctly → reward.\\n\\nIf it picks the wrong one → penalty.\\x0b Over time, it learns the best way to act for maximum reward.\\n\\n\\n\\nWhen used:\\n\\nWhen the goal is to make a sequence of decisions based on feedback.\\n\\nReal-life examples:\\x0bSelf-driving cars, game-playing AI, robots, recommendation systems.\\n\\n\\n\\nApplications of Machine Learning\\n\\n1. Automatic Language Translation\\x0b Apps like Google Translate use ML to understand and convert text or speech from one language to another, helping people communicate easily across languages.\\n\\n2. Medical Diagnosis\\x0b ML analyzes medical images and patient data to help doctors detect diseases like cancer or diabetes early and more accurately.\\n\\n3. Stock Market Trading\\x0b ML studies past stock data and market trends to predict price changes and help traders make faster, data-driven decisions.\\n\\n4. Online Food Delivery\\x0b Apps like Swiggy or Zomato use ML to predict delivery times and suggest restaurants or dishes you might like.\\n\\n\\n\\n\\n\\n5. Virtual Assistants\\x0b Siri and Alexa use ML to understand your voice commands and perform tasks like calling, texting, or playing music.\\n\\n6. Email Spam Detection\\x0b ML automatically filters out spam by learning what kinds of messages are unwanted or unsafe.\\n\\n7. Self-Driving Cars\\x0b ML helps cars recognize roads, traffic, and obstacles, allowing them to drive safely without human control.\\n\\n8. Product Recommendation\\x0b Amazon and Netflix use ML to suggest products or shows based on what you’ve liked before.\\n\\n9. Traffic Prediction\\x0b Google Maps uses ML to analyze real-time traffic data and suggest the quickest routes.\\n\\n10. Speech Recognition\\x0b ML turns spoken words into text, making voice typing and commands possible.\\n\\n11. Image Recognition\\x0b ML identifies faces, objects, or animals in pictures — used in security, healthcare, and social media.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321934b-e263-4369-bbfe-b5d5a300d421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b7fd15-1995-45e1-8eb7-7367dfe1c4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1e2c6e0-5880-4875-a1cf-528277270a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "629a5f62-92fa-4742-a4ee-47e30036da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1 = data[0]\n",
    "doc_2 = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e0145-ec9c-4cf9-9f3e-2141c3b1d757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ea22425-130f-4983-9972-77426a895768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\n    Tell me the core theme of the content below\\n    and explain how it is useful.\\n\\n    Content:\\n    {text}\\n    ')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Prompt\n",
    "prompt_1 = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Tell me the core theme of the content below\n",
    "    and explain how it is useful.\n",
    "\n",
    "    Content:\n",
    "    {text}\n",
    "    \"\"\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "prompt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8cc440f-dcda-4094-b618-24bc67a3ebc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StrOutputParser()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "744438c8-728a-43e3-8fad-8f86db7c3bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  summary_1: RunnableLambda(...)\n",
       "             | PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\n    Tell me the core theme of the content below\\n    and explain how it is useful.\\n\\n    Content:\\n    {text}\\n    ')\n",
       "             | ChatOllama(model='gemma:2b')\n",
       "             | StrOutputParser(),\n",
       "  summary_2: RunnableLambda(...)\n",
       "             | PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\n    Tell me the core theme of the content below\\n    and explain how it is useful.\\n\\n    Content:\\n    {text}\\n    ')\n",
       "             | ChatOllama(model='gemma:2b')\n",
       "             | StrOutputParser()\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "\n",
    "chain = RunnableParallel({\n",
    "    \"summary_1\": RunnableLambda(lambda x: {\"text\": x[\"doc_1\"]}) | prompt_1 | model | parser,\n",
    "    \"summary_2\": RunnableLambda(lambda x: {\"text\": x[\"doc_2\"]}) | prompt_1 | model | parser,\n",
    "})\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57c934-1b5f-427f-9e88-5f7f71248e69",
   "metadata": {},
   "source": [
    "so, x will be a dictionary of two passed pairs, in lambda func, we fetch the required data from x-dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ec8572e-2149-4c8f-b67d-638e94c1d6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary_1': 'Sure, here is the core theme of the content and its usefulness:\\n\\n**Core Theme: Feature Engineering is a crucial step in building accurate machine learning models.**\\n\\n**Useful Aspects:**\\n\\n- Feature engineering helps address the issue of data noise and missing values.\\n- It prepares data for the machine learning model by cleaning, encoding categorical and numerical data, and transforming features.\\n- Feature engineering can significantly improve model performance by improving the quality and consistency of data.\\n- It ensures that the model is trained on data that is relevant to the real-world application.\\n- By focusing on feature engineering, you can create features that capture important patterns and relationships in the data, leading to better model performance.\\n\\nOverall, feature engineering is an essential step in building robust and accurate machine learning models by cleaning, transforming, and creating features that effectively capture the underlying patterns and relationships in the data.', 'summary_2': '**Core Theme**: Machine learning (ML) is a branch of artificial intelligence (AI) that allows computers to learn from data and make predictions or decisions without being explicitly programmed.\\n\\n**How it is useful**:\\n\\n* Solves difficult problems: ML can find patterns and answers in situations that are too complex for humans to solve easily.\\n* Handles huge amounts of data: ML can study and learn from millions of data points much faster than people can.\\n* Automates repetitive tasks: ML can do the same kind of work over and over again without getting tired or making mistakes.\\n* Improves over time: The more data it sees, the smarter it becomes and the better its predictions get.'}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"doc_1\": doc_1.page_content,\n",
    "    \"doc_2\": doc_2.page_content,\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e84c70b-af17-4c6e-aba1-d729c9fc23ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here is the core theme of the content and its usefulness:\\n\\n**Core Theme: Feature Engineering is a crucial step in building accurate machine learning models.**\\n\\n**Useful Aspects:**\\n\\n- Feature engineering helps address the issue of data noise and missing values.\\n- It prepares data for the machine learning model by cleaning, encoding categorical and numerical data, and transforming features.\\n- Feature engineering can significantly improve model performance by improving the quality and consistency of data.\\n- It ensures that the model is trained on data that is relevant to the real-world application.\\n- By focusing on feature engineering, you can create features that capture important patterns and relationships in the data, leading to better model performance.\\n\\nOverall, feature engineering is an essential step in building robust and accurate machine learning models by cleaning, transforming, and creating features that effectively capture the underlying patterns and relationships in the data.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['summary_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8aacf984-ebd5-4774-8a66-837ff2a8e694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Core Theme**: Machine learning (ML) is a branch of artificial intelligence (AI) that allows computers to learn from data and make predictions or decisions without being explicitly programmed.\\n\\n**How it is useful**:\\n\\n* Solves difficult problems: ML can find patterns and answers in situations that are too complex for humans to solve easily.\\n* Handles huge amounts of data: ML can study and learn from millions of data points much faster than people can.\\n* Automates repetitive tasks: ML can do the same kind of work over and over again without getting tired or making mistakes.\\n* Improves over time: The more data it sees, the smarter it becomes and the better its predictions get.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['summary_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "631de545-e9f8-4024-b418-73bdec9f349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +------------------------------------+      \n",
      "     | Parallel<summary_1,summary_2>Input |      \n",
      "     +------------------------------------+      \n",
      "                ***           ***                \n",
      "              **                 **              \n",
      "            **                     **            \n",
      "    +--------+                    +--------+     \n",
      "    | Lambda |                    | Lambda |     \n",
      "    +--------+                    +--------+     \n",
      "          *                           *          \n",
      "          *                           *          \n",
      "          *                           *          \n",
      "+----------------+            +----------------+ \n",
      "| PromptTemplate |            | PromptTemplate | \n",
      "+----------------+            +----------------+ \n",
      "          *                           *          \n",
      "          *                           *          \n",
      "          *                           *          \n",
      "  +------------+                +------------+   \n",
      "  | ChatOllama |                | ChatOllama |   \n",
      "  +------------+                +------------+   \n",
      "          *                           *          \n",
      "          *                           *          \n",
      "          *                           *          \n",
      "+-----------------+          +-----------------+ \n",
      "| StrOutputParser |          | StrOutputParser | \n",
      "+-----------------+          +-----------------+ \n",
      "                ***           ***                \n",
      "                   **       **                   \n",
      "                     **   **                     \n",
      "    +-------------------------------------+      \n",
      "    | Parallel<summary_1,summary_2>Output |      \n",
      "    +-------------------------------------+      \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d62573-9ee2-428e-b262-5a1c25dccfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
